{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paramaters\n",
    "\n",
    "In this cell we will define a plethera of paramaters to describe how to run the rest of this notebook including paramaters on model construction, testing, layer size, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_dir        = \"/home/jovyan/local-volume-claim/notebooks/data/landmark_images/\"\n",
    "target_dir       = \"/home/jovyan/local-volume-claim/notebooks/data/original_images/\"\n",
    "output_dir       = \"./models/face2face-model/\"\n",
    "\n",
    "max_steps        = 50\n",
    "max_epochs       = 100\n",
    "batch_size       = 5\n",
    "channels         = 3\n",
    "\n",
    "summary_freq     = 50\n",
    "display_freq     = 100\n",
    "progress_freq    = 200\n",
    "save_freq        = 2000\n",
    "trace_freq       = 0\n",
    "\n",
    "\n",
    "separable_conv   = True\n",
    "aspect_ratio     = 1.0\n",
    "lab_colorization = False\n",
    "which_direction  = \"AtoB\" # choices=[\"AtoB\", \"BtoA\"])\n",
    "ngf              = 64\n",
    "NGF              = 64\n",
    "ndf              = 64\n",
    "scale_size       = 256\n",
    "no_flip          = False\n",
    "flip             = True\n",
    "lr               = 0.0002\n",
    "beta1            = 0.5\n",
    "l1_weight        = 100.0\n",
    "gan_weight       = 1.0\n",
    "output_filetype  = \"png\" # choices=[\"png\", \"jpeg\"])          \n",
    "input_filetype   = \"jpg\"\n",
    "EPS              = 1e-12\n",
    "CROP_SIZE        = 256\n",
    "seed             = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies\n",
    "\n",
    "In this cell we will import all the python modules needed to build a tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '10'\n",
    "\n",
    "import tensorflow as tf;tf.reset_default_graph()\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "## Set random seeds\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model containers\n",
    "\n",
    "In this next cell we will take advantage of pythons `namedtuple` object to store direct properties we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = collections.namedtuple(\"Model\", \"outputs, predict_real, predict_fake, discrim_loss, discrim_grads_and_vars, gen_loss_GAN, gen_loss_L1, gen_grads_and_vars, train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining process functions\n",
    "\n",
    "In this next cell we will define several utility functions in tensorflow for processing images in a standard way across the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "process"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    with tf.name_scope(\"preprocess\"):\n",
    "        # [0, 1] => [-1, 1]\n",
    "        return image * 2 - 1\n",
    "\n",
    "def deprocess(image):\n",
    "    with tf.name_scope(\"deprocess\"):\n",
    "        # [-1, 1] => [0, 1]\n",
    "        return (image + 1) / 2\n",
    "\n",
    "def preprocess_lab(lab):\n",
    "    with tf.name_scope(\"preprocess_lab\"):\n",
    "        L_chan, a_chan, b_chan = tf.unstack(lab, axis=2)\n",
    "        # L_chan: black and white with input range [0, 100]\n",
    "        # a_chan/b_chan: color channels with input range ~[-110, 110], not exact\n",
    "        # [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]\n",
    "        return [L_chan / 50 - 1, a_chan / 110, b_chan / 110]\n",
    "\n",
    "def deprocess_lab(L_chan, a_chan, b_chan):\n",
    "    with tf.name_scope(\"deprocess_lab\"):\n",
    "        # this is axis=3 instead of axis=2 because we process individual images but deprocess batches\n",
    "        return tf.stack([(L_chan + 1) / 2 * 100, a_chan * 110, b_chan * 110], axis=3)\n",
    "    \n",
    "def augment(image, brightness):\n",
    "    # (a, b) color channels, combine with L channel and convert to rgb\n",
    "    a_chan, b_chan = tf.unstack(image, axis=3)\n",
    "    L_chan = tf.squeeze(brightness, axis=3)\n",
    "    lab = deprocess_lab(L_chan, a_chan, b_chan)\n",
    "    rgb = lab_to_rgb(lab)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution layers\n",
    "\n",
    "Now that we have defined several utility functions, we will now define our convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "conv"
    ]
   },
   "outputs": [],
   "source": [
    "def discrim_conv(batch_input, out_channels, stride):\n",
    "    padded_input = tf.pad(batch_input, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"CONSTANT\")\n",
    "    return tf.layers.conv2d(padded_input, \n",
    "                            out_channels, \n",
    "                            kernel_size=4, \n",
    "                            strides=(stride, stride), \n",
    "                            padding=\"valid\",\n",
    "                            kernel_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "\n",
    "def gen_conv(batch_input, out_channels, dtype=tf.float32):\n",
    "    # generator/encoder_1/separable_conv2d/depthwise_kernel:0\n",
    "    # [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]\n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    if separable_conv:\n",
    "        return tf.layers.separable_conv2d(batch_input, \n",
    "                                          out_channels, \n",
    "                                          kernel_size=4, \n",
    "                                          strides=(2, 2), \n",
    "                                          padding=\"same\", \n",
    "                                          depthwise_initializer=initializer, \n",
    "                                          pointwise_initializer=initializer)\n",
    "    else:\n",
    "        return tf.layers.conv2d(batch_input, \n",
    "                                out_channels, \n",
    "                                kernel_size=4, \n",
    "                                strides=(2, 2), \n",
    "                                padding=\"same\",\n",
    "                                kernel_initializer=initializer)\n",
    "\n",
    "def gen_deconv(batch_input, out_channels):\n",
    "    # [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]\n",
    "    initializer = tf.random_normal_initializer(0, 0.02)\n",
    "    if separable_conv:\n",
    "        _b, h, w, _c = batch_input.shape\n",
    "        resized_input = tf.image.resize_images(batch_input, \n",
    "                                               tf.constant([h * 2, w * 2], dtype=tf.int32), \n",
    "                                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        return tf.layers.separable_conv2d(resized_input, out_channels, kernel_size=4, strides=(1, 1), padding=\"same\", depthwise_initializer=initializer, pointwise_initializer=initializer)\n",
    "    else:\n",
    "        return tf.layers.conv2d_transpose(batch_input, out_channels, kernel_size=4, strides=(2, 2), padding=\"same\", kernel_initializer=initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "Now that each of our main layer functions have been constructed we will now define some handy utility functions which will help us add unique utility to our model to increase it's overall efficency and specialization compared to what `tensorflow` gives us out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "util"
    ]
   },
   "outputs": [],
   "source": [
    "def lrelu(x, a):\n",
    "    with tf.name_scope(\"lrelu\"):\n",
    "        # adding these together creates the leak part and linear part\n",
    "        # then cancels them out by subtracting/adding an absolute value term\n",
    "        # leak: a*x/2 - a*abs(x)/2\n",
    "        # linear: x/2 + abs(x)/2\n",
    "\n",
    "        # this block looks like it has 2 inputs on the graph unless we do this\n",
    "        x = tf.identity(x)\n",
    "        return (0.5 * (1 + a)) * x + (0.5 * (1 - a)) * tf.abs(x)\n",
    "\n",
    "def batchnorm(inputs):\n",
    "    return tf.layers.batch_normalization(inputs, axis=3, epsilon=1e-5, momentum=0.1, training=True, gamma_initializer=tf.random_normal_initializer(1.0, 0.02))\n",
    "\n",
    "def check_image(image):\n",
    "    assertion = tf.assert_equal(tf.shape(image)[-1], 3, message=\"image must have 3 color channels\")\n",
    "    with tf.control_dependencies([assertion]):\n",
    "        image = tf.identity(image)\n",
    "\n",
    "    if image.get_shape().ndims not in (3, 4):\n",
    "        raise ValueError(\"image must be either 3 or 4 dimensions\")\n",
    "\n",
    "    # make the last dimension 3 so that you can unstack the colors\n",
    "    shape = list(image.get_shape())\n",
    "    shape[-1] = 3\n",
    "    image.set_shape(shape)\n",
    "    return image\n",
    "\n",
    "# based on https://github.com/torch/image/blob/9f65c30167b2048ecbe8b7befdc6b2d6d12baee9/generic/image.c\n",
    "def rgb_to_lab(srgb):\n",
    "    with tf.name_scope(\"rgb_to_lab\"):\n",
    "        srgb = check_image(srgb)\n",
    "        srgb_pixels = tf.reshape(srgb, [-1, 3])\n",
    "\n",
    "        with tf.name_scope(\"srgb_to_xyz\"):\n",
    "            linear_mask = tf.cast(srgb_pixels <= 0.04045, dtype=tf.float32)\n",
    "            exponential_mask = tf.cast(srgb_pixels > 0.04045, dtype=tf.float32)\n",
    "            rgb_pixels = (srgb_pixels / 12.92 * linear_mask) + (((srgb_pixels + 0.055) / 1.055) ** 2.4) * exponential_mask\n",
    "            rgb_to_xyz = tf.constant([\n",
    "                #    X        Y          Z\n",
    "                [0.412453, 0.212671, 0.019334], # R\n",
    "                [0.357580, 0.715160, 0.119193], # G\n",
    "                [0.180423, 0.072169, 0.950227], # B\n",
    "            ])\n",
    "            xyz_pixels = tf.matmul(rgb_pixels, rgb_to_xyz)\n",
    "\n",
    "        # https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
    "        with tf.name_scope(\"xyz_to_cielab\"):\n",
    "            # convert to fx = f(X/Xn), fy = f(Y/Yn), fz = f(Z/Zn)\n",
    "\n",
    "            # normalize for D65 white point\n",
    "            xyz_normalized_pixels = tf.multiply(xyz_pixels, [1/0.950456, 1.0, 1/1.088754])\n",
    "\n",
    "            epsilon = 6/29\n",
    "            linear_mask = tf.cast(xyz_normalized_pixels <= (epsilon**3), dtype=tf.float32)\n",
    "            exponential_mask = tf.cast(xyz_normalized_pixels > (epsilon**3), dtype=tf.float32)\n",
    "            fxfyfz_pixels = (xyz_normalized_pixels / (3 * epsilon**2) + 4/29) * linear_mask + (xyz_normalized_pixels ** (1/3)) * exponential_mask\n",
    "\n",
    "            # convert to lab\n",
    "            fxfyfz_to_lab = tf.constant([\n",
    "                #  l       a       b\n",
    "                [  0.0,  500.0,    0.0], # fx\n",
    "                [116.0, -500.0,  200.0], # fy\n",
    "                [  0.0,    0.0, -200.0], # fz\n",
    "            ])\n",
    "            lab_pixels = tf.matmul(fxfyfz_pixels, fxfyfz_to_lab) + tf.constant([-16.0, 0.0, 0.0])\n",
    "\n",
    "        return tf.reshape(lab_pixels, tf.shape(srgb))\n",
    "\n",
    "\n",
    "def lab_to_rgb(lab):\n",
    "    with tf.name_scope(\"lab_to_rgb\"):\n",
    "        lab = check_image(lab)\n",
    "        lab_pixels = tf.reshape(lab, [-1, 3])\n",
    "\n",
    "        # https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
    "        with tf.name_scope(\"cielab_to_xyz\"):\n",
    "            # convert to fxfyfz\n",
    "            lab_to_fxfyfz = tf.constant([\n",
    "                #   fx      fy        fz\n",
    "                [1/116.0, 1/116.0,  1/116.0], # l\n",
    "                [1/500.0,     0.0,      0.0], # a\n",
    "                [    0.0,     0.0, -1/200.0], # b\n",
    "            ])\n",
    "            fxfyfz_pixels = tf.matmul(lab_pixels + tf.constant([16.0, 0.0, 0.0]), lab_to_fxfyfz)\n",
    "\n",
    "            # convert to xyz\n",
    "            epsilon = 6/29\n",
    "            linear_mask = tf.cast(fxfyfz_pixels <= epsilon, dtype=tf.float32)\n",
    "            exponential_mask = tf.cast(fxfyfz_pixels > epsilon, dtype=tf.float32)\n",
    "            xyz_pixels = (3 * epsilon**2 * (fxfyfz_pixels - 4/29)) * linear_mask + (fxfyfz_pixels ** 3) * exponential_mask\n",
    "\n",
    "            # denormalize for D65 white point\n",
    "            xyz_pixels = tf.multiply(xyz_pixels, [0.950456, 1.0, 1.088754])\n",
    "\n",
    "        with tf.name_scope(\"xyz_to_srgb\"):\n",
    "            xyz_to_rgb = tf.constant([\n",
    "                #     r           g          b\n",
    "                [ 3.2404542, -0.9692660,  0.0556434], # x\n",
    "                [-1.5371385,  1.8760108, -0.2040259], # y\n",
    "                [-0.4985314,  0.0415560,  1.0572252], # z\n",
    "            ])\n",
    "            rgb_pixels = tf.matmul(xyz_pixels, xyz_to_rgb)\n",
    "            # avoid a slightly negative number messing up the conversion\n",
    "            rgb_pixels = tf.clip_by_value(rgb_pixels, 0.0, 1.0)\n",
    "            linear_mask = tf.cast(rgb_pixels <= 0.0031308, dtype=tf.float32)\n",
    "            exponential_mask = tf.cast(rgb_pixels > 0.0031308, dtype=tf.float32)\n",
    "            srgb_pixels = (rgb_pixels * 12.92 * linear_mask) + ((rgb_pixels ** (1/2.4) * 1.055) - 0.055) * exponential_mask\n",
    "\n",
    "        return tf.reshape(srgb_pixels, tf.shape(lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our data\n",
    "\n",
    "Now that alot of these utility functions have been defined. We will make use of them when we load data from our input directory. To do this we will create a simple `load_examples` function which will look in out specifies input directory and return the named tuple container we defined earlier as our container.\n",
    "\n",
    "These data format we will be using is images of `.jpg` or `.png` variety. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.randint(0, 2**31 - 1)\n",
    "def transform(image):\n",
    "    r = image\n",
    "\n",
    "    # area produces a nice downscaling, but does nearest neighbor for upscaling\n",
    "    # assume we're going to be doing downscaling here\n",
    "    r = tf.image.resize_images(r, [scale_size, scale_size], method=tf.image.ResizeMethod.AREA)\n",
    "    return r\n",
    "\n",
    "def create_image_iterator(dirs):\n",
    "\n",
    "    ## Identify data type\n",
    "    if input_filetype == \"png\":\n",
    "        decode = tf.image.decode_png\n",
    "    elif input_filetype == \"jpg\":\n",
    "        decode = tf.image.decode_jpeg\n",
    "    else:\n",
    "        raise Exception(\"Unknown input filetype\")\n",
    "\n",
    "    def create_image_dataset(filename_dataset):\n",
    "        ## Convert data via mapping\n",
    "        with tf.name_scope(\"decode\"):\n",
    "            image_dataset = filename_dataset.map(lambda x:\n",
    "                                                 decode(tf.read_file(x), channels=channels))\n",
    "        with tf.name_scope(\"convert_preprocess\"):\n",
    "            image_dataset = image_dataset.map(lambda x:\n",
    "                                              preprocess(tf.image.convert_image_dtype(x,dtype=tf.float32)))\n",
    "        with tf.name_scope(\"transform\"):\n",
    "            image_dataset = image_dataset.map(lambda x:\n",
    "                                              transform(x))\n",
    "\n",
    "        return image_dataset\n",
    "    \n",
    "    glob_files = [glob.glob(os.path.join(d,\"**/**/*.%s\"%input_filetype)) for d in dirs]\n",
    "    sorted_glob_files = [sorted(d, key=os.path.basename) for d in glob_files]\n",
    "    assert len(set([len(i) for i in sorted_glob_files])) > 0, \"All dataset dirs must be the same size\"\n",
    "    \n",
    "    filename_datasets = [tf.data.Dataset.from_tensor_slices(d) for d in sorted_glob_files]\n",
    "    image_datasets = [create_image_dataset(fd) for fd in filename_datasets]\n",
    "    image_datasets = tf.data.Dataset.zip(tuple(id for id in image_datasets))\n",
    "\n",
    "    ## Create repetitions and batches\n",
    "    image_datasets = image_datasets.repeat(max_epochs).batch(batch_size=batch_size)\n",
    "    \n",
    "    ## Create iterator form datasets\n",
    "    iterator = image_datasets.make_one_shot_iterator()\n",
    "    \n",
    "    ## Create dataset size from files\n",
    "    dataset_size = len(sorted_glob_files[0])\n",
    "\n",
    "    return dataset_size, image_datasets, iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the generator\n",
    "\n",
    "In this next cell we will create the `G` in `GAN`. This model consists of an autoencoder of which we will return the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "gen"
    ]
   },
   "outputs": [],
   "source": [
    "def create_generator(generator_inputs, generator_outputs_channels, ngf=64):\n",
    "    layers = []\n",
    "\n",
    "    # encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]\n",
    "    with tf.variable_scope(\"encoder_1\"):\n",
    "        output = gen_conv(generator_inputs, ngf)\n",
    "        layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        ngf * 2, # encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]\n",
    "        ngf * 4, # encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]\n",
    "        ngf * 8, # encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]\n",
    "        ngf * 8, # encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]\n",
    "        ngf * 8, # encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]\n",
    "        ngf * 8, # encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]\n",
    "        ngf * 8, # encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]\n",
    "    ]\n",
    "\n",
    "    for out_channels in layer_specs:\n",
    "        with tf.variable_scope(\"encoder_%d\" % (len(layers) + 1)):\n",
    "            rectified = lrelu(layers[-1], 0.2)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]\n",
    "            convolved = gen_conv(rectified, out_channels)\n",
    "            output = batchnorm(convolved)\n",
    "            layers.append(output)\n",
    "\n",
    "    layer_specs = [\n",
    "        (ngf * 8, 0.5),   # decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]\n",
    "        (ngf * 8, 0.5),   # decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]\n",
    "        (ngf * 8, 0.5),   # decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]\n",
    "        (ngf * 8, 0.0),   # decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]\n",
    "        (ngf * 4, 0.0),   # decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]\n",
    "        (ngf * 2, 0.0),   # decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]\n",
    "        (ngf, 0.0),       # decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]\n",
    "    ]\n",
    "\n",
    "    # generator/encoder_1/separable_conv2d/depthwise_kernel:0\n",
    "    num_encoder_layers = len(layers)\n",
    "    for decoder_layer, (out_channels, dropout) in enumerate(layer_specs):\n",
    "        skip_layer = num_encoder_layers - decoder_layer - 1\n",
    "        with tf.variable_scope(\"decoder_%d\" % (skip_layer + 1)):\n",
    "            if decoder_layer == 0:\n",
    "                # first decoder layer doesn't have skip connections\n",
    "                # since it is directly connected to the skip_layer\n",
    "                input = layers[-1]\n",
    "            else:\n",
    "                input = tf.concat([layers[-1], layers[skip_layer]], axis=3)\n",
    "\n",
    "            rectified = tf.nn.relu(input)\n",
    "            # [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]\n",
    "            output = gen_deconv(rectified, out_channels)\n",
    "            output = batchnorm(output)\n",
    "\n",
    "            if dropout > 0.0:\n",
    "                output = tf.nn.dropout(output, keep_prob=1 - dropout)\n",
    "\n",
    "            layers.append(output)\n",
    "\n",
    "    # decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]\n",
    "    with tf.variable_scope(\"decoder_1\"):\n",
    "        input = tf.concat([layers[-1], layers[0]], axis=3)\n",
    "        rectified = tf.nn.relu(input)\n",
    "        output = gen_deconv(rectified, generator_outputs_channels)\n",
    "        output = tf.tanh(output)\n",
    "        layers.append(output)\n",
    "\n",
    "    return layers[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the discriminator\n",
    "\n",
    "In the next cell we will now create the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "disc"
    ]
   },
   "outputs": [],
   "source": [
    "def create_discriminator(discrim_inputs, discrim_targets):\n",
    "    n_layers = 3\n",
    "    layers = []\n",
    "    \n",
    "    # 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]\n",
    "    input = tf.concat([discrim_inputs, discrim_targets], axis=3)\n",
    "\n",
    "    # layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]\n",
    "    with tf.variable_scope(\"layer_1\"):\n",
    "        convolved = discrim_conv(input, ndf, stride=2)\n",
    "        rectified = lrelu(convolved, 0.2)\n",
    "        layers.append(rectified)\n",
    "\n",
    "    # layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]\n",
    "    # layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]\n",
    "    # layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]\n",
    "    for i in range(n_layers):\n",
    "        with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "            out_channels = ndf * min(2**(i+1), 8)\n",
    "            stride = 1 if i == n_layers - 1 else 2  # last layer here has stride 1\n",
    "            convolved = discrim_conv(layers[-1], out_channels, stride=stride)\n",
    "            normalized = batchnorm(convolved)\n",
    "            rectified = lrelu(normalized, 0.2)\n",
    "            layers.append(rectified)\n",
    "\n",
    "    # layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]\n",
    "    with tf.variable_scope(\"layer_%d\" % (len(layers) + 1)):\n",
    "        convolved = discrim_conv(rectified, out_channels=1, stride=1)\n",
    "        output = tf.sigmoid(convolved)\n",
    "        layers.append(output)\n",
    "\n",
    "    return layers[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "\n",
    "now we will combine the creation of the generator and discriminator to create the GAN we will be training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "model"
    ]
   },
   "outputs": [],
   "source": [
    "def create_model(inputs, targets):\n",
    "    with tf.variable_scope(\"generator\"):\n",
    "        out_channels = channels # int(targets.get_shape()[-1])\n",
    "        outputs = create_generator(inputs, out_channels)\n",
    "\n",
    "    # create two copies of discriminator, one for real pairs and one for fake pairs\n",
    "    # they share the same underlying variables\n",
    "    with tf.name_scope(\"real_discriminator\"):\n",
    "        with tf.variable_scope(\"discriminator\"):\n",
    "            # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "            predict_real = create_discriminator(inputs, targets)\n",
    "\n",
    "    with tf.name_scope(\"fake_discriminator\"):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=True):\n",
    "            # 2x [batch, height, width, channels] => [batch, 30, 30, 1]\n",
    "            predict_fake = create_discriminator(inputs, outputs)\n",
    "\n",
    "    with tf.name_scope(\"discriminator_loss\"):\n",
    "        # minimizing -tf.log will try to get inputs to 1\n",
    "        # predict_real => 1\n",
    "        # predict_fake => 0\n",
    "        discrim_loss = tf.reduce_mean(-(tf.log(predict_real + EPS) + tf.log(1 - predict_fake + EPS)))\n",
    "\n",
    "    with tf.name_scope(\"generator_loss\"):\n",
    "        # predict_fake => 1\n",
    "        # abs(targets - outputs) => 0\n",
    "        gen_loss_GAN = tf.reduce_mean(-tf.log(predict_fake + EPS))\n",
    "        gen_loss_L1 = tf.reduce_mean(tf.abs(targets - outputs))\n",
    "        gen_loss = gen_loss_GAN * gan_weight + gen_loss_L1 * l1_weight\n",
    "\n",
    "    with tf.name_scope(\"discriminator_train\"):\n",
    "        discrim_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"discriminator\")]\n",
    "        discrim_optim = tf.train.AdamOptimizer(lr, beta1)\n",
    "        discrim_grads_and_vars = discrim_optim.compute_gradients(discrim_loss, var_list=discrim_tvars)\n",
    "        discrim_train = discrim_optim.apply_gradients(discrim_grads_and_vars)\n",
    "\n",
    "    with tf.name_scope(\"generator_train\"):\n",
    "        with tf.control_dependencies([discrim_train]):\n",
    "            gen_tvars = [var for var in tf.trainable_variables() if var.name.startswith(\"generator\")]\n",
    "            gen_optim = tf.train.AdamOptimizer(lr, beta1)\n",
    "            gen_grads_and_vars = gen_optim.compute_gradients(gen_loss, var_list=gen_tvars)\n",
    "            gen_train = gen_optim.apply_gradients(gen_grads_and_vars)\n",
    "\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.99)\n",
    "    update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1])\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    incr_global_step = tf.assign(global_step, global_step+1)\n",
    "\n",
    "    return Model(\n",
    "        predict_real=predict_real,\n",
    "        predict_fake=predict_fake,\n",
    "        discrim_loss=ema.average(discrim_loss),\n",
    "        discrim_grads_and_vars=discrim_grads_and_vars,\n",
    "        gen_loss_GAN=ema.average(gen_loss_GAN),\n",
    "        gen_loss_L1=ema.average(gen_loss_L1),\n",
    "        gen_grads_and_vars=gen_grads_and_vars,\n",
    "        outputs=outputs,\n",
    "        train=tf.group(update_losses, incr_global_step, gen_train),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model image output\n",
    "\n",
    "When we are training we would like to see how our model is performing via visual and visceral feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(fetches, step=None):\n",
    "    \n",
    "    ## create image directory\n",
    "    image_dir = os.path.join(output_dir, \"images\")\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "    filesets = []\n",
    "    for i, (kind, content) in enumerate(fetches[\"display\"].items()):\n",
    "        \n",
    "        fileset = {\"name\": kind, \"step\": step}\n",
    "\n",
    "        filename = kind + \".png\"\n",
    "        if step is not None:\n",
    "            filename = \"%08d-%s\" % (step, filename)\n",
    "        \n",
    "        fileset[kind] = filename\n",
    "        out_path = os.path.join(image_dir, filename)\n",
    "        contents = fetches[\"display\"][kind]\n",
    "        filesets.append(fileset)\n",
    "        \n",
    "    return filesets\n",
    "\n",
    "\n",
    "def append_index(filesets, step=False):\n",
    "    index_path = os.path.join(output_dir, \"index.html\")\n",
    "    if os.path.exists(index_path):\n",
    "        index = open(index_path, \"a\")\n",
    "    else:\n",
    "        index = open(index_path, \"w\")\n",
    "        index.write(\"<html><body><table><tr>\")\n",
    "        if step:\n",
    "            index.write(\"<th>step</th>\")\n",
    "        index.write(\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\")\n",
    "\n",
    "    for fileset in filesets:\n",
    "        index.write(\"<tr>\")\n",
    "\n",
    "        if step:\n",
    "            index.write(\"<td>%d</td>\" % fileset[\"step\"])\n",
    "        index.write(\"<td>%s</td>\" % fileset[\"name\"])\n",
    "        index.write(\"<td><img src='images/%s'></td>\" % fileset[\"name\"])\n",
    "        index.write(\"</tr>\")\n",
    "    return index_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup and evaluation\n",
    "\n",
    "We now have all the needed functions to define our model, we will now start to execute it's functionality based on the mode we have defined in our paramaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for model\n",
    "\n",
    "In this next cell we will use the load_examples function to load our training data into local memory. We will then print some high level properties about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "In this next cell we will directly create our model from the examples inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "assert len(gpus) > 0, \"GPUS should be available :(\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/device:CPU:0'):\n",
    "    dataset_size, global_image_dataset, global_image_iterator = create_image_iterator(dirs = [input_dir, target_dir])\n",
    "    input_image_next, target_image_next = global_image_iterator.get_next()\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model = create_model(input_image_next, target_image_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = deprocess(input_image_next)\n",
    "targets = deprocess(target_image_next)\n",
    "outputs = deprocess(model.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model visibility\n",
    "\n",
    "In order to see the output in a proper format that is viewable on most systems, we define a convert function to apply to the input, output, and target images. We then define a display_fetches output that will encode all of the input, output, and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(image):\n",
    "    if aspect_ratio != 1.0:\n",
    "        # upscale to correct aspect ratio\n",
    "        size = [CROP_SIZE, int(round(CROP_SIZE * aspect_ratio))]\n",
    "        image = tf.image.resize_images(image, size=size, method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "    return tf.image.convert_image_dtype(image, dtype=tf.uint8, saturate=True)\n",
    "\n",
    "# reverse any processing on images so they can be written to disk or displayed to user\n",
    "with tf.name_scope(\"convert_inputs\"):\n",
    "    converted_inputs = convert(inputs)\n",
    "\n",
    "with tf.name_scope(\"convert_targets\"):\n",
    "    converted_targets = convert(targets)\n",
    "\n",
    "with tf.name_scope(\"convert_outputs\"):\n",
    "    converted_outputs = convert(outputs)\n",
    "\n",
    "with tf.name_scope(\"encode_images\"):\n",
    "    display_fetches = {\n",
    "        \"inputs\": tf.map_fn(tf.image.encode_png, converted_inputs, dtype=tf.string, name=\"input_pngs\"),\n",
    "        \"targets\": tf.map_fn(tf.image.encode_png, converted_targets, dtype=tf.string, name=\"target_pngs\"),\n",
    "        \"outputs\": tf.map_fn(tf.image.encode_png, converted_outputs, dtype=tf.string, name=\"output_pngs\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries\n",
    "\n",
    "In the next cell we will define multiple summaries to provide insight into the model. Including image outputs and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summaries\n",
    "with tf.name_scope(\"inputs_summary\"):\n",
    "    tf.summary.image(\"inputs\", converted_inputs)\n",
    "\n",
    "with tf.name_scope(\"targets_summary\"):\n",
    "    tf.summary.image(\"targets\", converted_targets)\n",
    "\n",
    "with tf.name_scope(\"outputs_summary\"):\n",
    "    tf.summary.image(\"outputs\", converted_outputs)\n",
    "\n",
    "with tf.name_scope(\"predict_real_summary\"):\n",
    "    tf.summary.image(\"predict_real\", tf.image.convert_image_dtype(model.predict_real, dtype=tf.uint8))\n",
    "\n",
    "with tf.name_scope(\"predict_fake_summary\"):\n",
    "    tf.summary.image(\"predict_fake\", tf.image.convert_image_dtype(model.predict_fake, dtype=tf.uint8))\n",
    "\n",
    "tf.summary.scalar(\"discriminator_loss\", model.discrim_loss)\n",
    "tf.summary.scalar(\"generator_loss_GAN\", model.gen_loss_GAN)\n",
    "tf.summary.scalar(\"generator_loss_L1\", model.gen_loss_L1)\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name + \"/values\", var)\n",
    "\n",
    "for grad, var in model.discrim_grads_and_vars + model.gen_grads_and_vars:\n",
    "    tf.summary.histogram(var.op.name + \"/gradients\", grad)\n",
    "    \n",
    "with tf.name_scope(\"parameter_count\"):\n",
    "    parameter_count = tf.reduce_sum([tf.reduce_prod(tf.shape(v)) for v in tf.trainable_variables()])\n",
    "    \n",
    "summary_merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "In the next cell we will train our model and save our intermediate checkpoints to a file and output log summaries to out output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "parameter_count = 6314292\n",
      "No model to load ...\n",
      "Training has started! ...\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 1  step 200  datum 15 global_step 200 image/sec 1.1  remaining 0m\n",
      "discrim_loss 0.8497088\n",
      "gen_loss_GAN 1.3617435\n",
      "gen_loss_L1 0.0956818\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 1  step 400  datum 35 global_step 400 image/sec 0.6  remaining 0m\n",
      "discrim_loss 0.818709\n",
      "gen_loss_GAN 1.514611\n",
      "gen_loss_L1 0.095655695\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 2  step 196  datum 55 global_step 600 image/sec 0.4  remaining 0m\n",
      "discrim_loss 0.7857881\n",
      "gen_loss_GAN 1.5809641\n",
      "gen_loss_L1 0.07706506\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 2  step 396  datum 75 global_step 800 image/sec 0.3  remaining 0m\n",
      "discrim_loss 0.65065706\n",
      "gen_loss_GAN 1.8221561\n",
      "gen_loss_L1 0.09177157\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 3  step 192  datum 95 global_step 1000 image/sec 0.2  remaining 0m\n",
      "discrim_loss 0.7153637\n",
      "gen_loss_GAN 1.8543439\n",
      "gen_loss_L1 0.07698143\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 3  step 392  datum 115 global_step 1200 image/sec 0.2  remaining 0m\n",
      "discrim_loss 0.7666941\n",
      "gen_loss_GAN 1.8394775\n",
      "gen_loss_L1 0.09214562\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 4  step 188  datum 135 global_step 1400 image/sec 0.2  remaining 0m\n",
      "discrim_loss 0.54369146\n",
      "gen_loss_GAN 2.0611508\n",
      "gen_loss_L1 0.079759516\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 4  step 388  datum 155 global_step 1600 image/sec 0.1  remaining 0m\n",
      "discrim_loss 0.5842357\n",
      "gen_loss_GAN 2.3004541\n",
      "gen_loss_L1 0.09326848\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 5  step 184  datum 175 global_step 1800 image/sec 0.1  remaining 0m\n",
      "discrim_loss 0.6216538\n",
      "gen_loss_GAN 2.065669\n",
      "gen_loss_L1 0.081503615\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 5  step 384  datum 195 global_step 2000 image/sec 0.1  remaining 0m\n",
      "discrim_loss 0.6413248\n",
      "gen_loss_GAN 2.31135\n",
      "gen_loss_L1 0.088114105\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 6  step 180  datum 215 global_step 2200 image/sec 0.1  remaining 0m\n",
      "discrim_loss 0.52001655\n",
      "gen_loss_GAN 2.339063\n",
      "gen_loss_L1 0.08060238\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 6  step 380  datum 235 global_step 2400 image/sec 0.1  remaining 0m\n",
      "discrim_loss 0.7582908\n",
      "gen_loss_GAN 2.2493286\n",
      "gen_loss_L1 0.08433681\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 7  step 176  datum 255 global_step 2600 image/sec 0.1  remaining 0m\n",
      "discrim_loss 0.4945027\n",
      "gen_loss_GAN 2.4549527\n",
      "gen_loss_L1 0.078996725\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 7  step 376  datum 275 global_step 2800 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.5553033\n",
      "gen_loss_GAN 2.4681187\n",
      "gen_loss_L1 0.08251112\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 8  step 172  datum 295 global_step 3000 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.38677135\n",
      "gen_loss_GAN 2.712686\n",
      "gen_loss_L1 0.077253714\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 8  step 372  datum 315 global_step 3200 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.7594452\n",
      "gen_loss_GAN 2.3944848\n",
      "gen_loss_L1 0.08458107\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 9  step 168  datum 335 global_step 3400 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.4611745\n",
      "gen_loss_GAN 2.6322734\n",
      "gen_loss_L1 0.079525314\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 9  step 368  datum 355 global_step 3600 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.52649504\n",
      "gen_loss_GAN 2.542239\n",
      "gen_loss_L1 0.08335613\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 10  step 164  datum 375 global_step 3800 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.4913586\n",
      "gen_loss_GAN 2.8090775\n",
      "gen_loss_L1 0.07936869\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 10  step 364  datum 395 global_step 4000 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.48272964\n",
      "gen_loss_GAN 2.5914311\n",
      "gen_loss_L1 0.07938199\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 11  step 160  datum 415 global_step 4200 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.9932907\n",
      "gen_loss_GAN 2.5769944\n",
      "gen_loss_L1 0.07759183\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 11  step 360  datum 435 global_step 4400 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.60210156\n",
      "gen_loss_GAN 2.440032\n",
      "gen_loss_L1 0.07687846\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 12  step 156  datum 455 global_step 4600 image/sec 0.1  remaining 1m\n",
      "discrim_loss 0.39458704\n",
      "gen_loss_GAN 2.9645643\n",
      "gen_loss_L1 0.079524964\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 12  step 356  datum 475 global_step 4800 image/sec 0.1  remaining 1m\n",
      "discrim_loss 1.0878506\n",
      "gen_loss_GAN 1.853253\n",
      "gen_loss_L1 0.072702646\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 13  step 152  datum 495 global_step 5000 image/sec 0.0  remaining 1m\n",
      "discrim_loss 0.5943451\n",
      "gen_loss_GAN 2.5694427\n",
      "gen_loss_L1 0.07609208\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 13  step 352  datum 515 global_step 5200 image/sec 0.0  remaining 1m\n",
      "discrim_loss 0.9479427\n",
      "gen_loss_GAN 2.1686313\n",
      "gen_loss_L1 0.069451325\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 14  step 148  datum 535 global_step 5400 image/sec 0.0  remaining 1m\n",
      "discrim_loss 0.559964\n",
      "gen_loss_GAN 2.6303468\n",
      "gen_loss_L1 0.07773077\n",
      "-------------------------\n",
      "recording summary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 14  step 348  datum 555 global_step 5600 image/sec 0.0  remaining 1m\n",
      "discrim_loss 0.45811945\n",
      "gen_loss_GAN 2.7557523\n",
      "gen_loss_L1 0.06770127\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 15  step 144  datum 575 global_step 5800 image/sec 0.0  remaining 1m\n",
      "discrim_loss 0.36797342\n",
      "gen_loss_GAN 3.0643728\n",
      "gen_loss_L1 0.07570643\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 15  step 344  datum 595 global_step 6000 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.67117673\n",
      "gen_loss_GAN 2.8199196\n",
      "gen_loss_L1 0.06577058\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 16  step 140  datum 615 global_step 6200 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.48503995\n",
      "gen_loss_GAN 3.2397244\n",
      "gen_loss_L1 0.07786433\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 16  step 340  datum 635 global_step 6400 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.3767469\n",
      "gen_loss_GAN 3.1018445\n",
      "gen_loss_L1 0.06642685\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 17  step 136  datum 655 global_step 6600 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.30528748\n",
      "gen_loss_GAN 3.5822437\n",
      "gen_loss_L1 0.07989619\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 17  step 336  datum 675 global_step 6800 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.33137172\n",
      "gen_loss_GAN 3.3529913\n",
      "gen_loss_L1 0.06974415\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 18  step 132  datum 695 global_step 7000 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.23430435\n",
      "gen_loss_GAN 3.6222796\n",
      "gen_loss_L1 0.080288395\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 18  step 332  datum 715 global_step 7200 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.3031588\n",
      "gen_loss_GAN 3.5203104\n",
      "gen_loss_L1 0.07005541\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 19  step 128  datum 735 global_step 7400 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.25677723\n",
      "gen_loss_GAN 3.8090756\n",
      "gen_loss_L1 0.08175258\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 19  step 328  datum 755 global_step 7600 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.7190152\n",
      "gen_loss_GAN 2.7518501\n",
      "gen_loss_L1 0.06709823\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 20  step 124  datum 775 global_step 7800 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.37659204\n",
      "gen_loss_GAN 3.4079916\n",
      "gen_loss_L1 0.08206936\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 20  step 324  datum 795 global_step 8000 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.28075224\n",
      "gen_loss_GAN 3.5113802\n",
      "gen_loss_L1 0.07279904\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 21  step 120  datum 815 global_step 8200 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.36099416\n",
      "gen_loss_GAN 3.5980208\n",
      "gen_loss_L1 0.08405657\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 21  step 320  datum 835 global_step 8400 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.4471833\n",
      "gen_loss_GAN 3.1288757\n",
      "gen_loss_L1 0.070072405\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 22  step 116  datum 855 global_step 8600 image/sec 0.0  remaining 2m\n",
      "discrim_loss 0.5303146\n",
      "gen_loss_GAN 3.3305428\n",
      "gen_loss_L1 0.080378905\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 22  step 316  datum 875 global_step 8800 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.2964255\n",
      "gen_loss_GAN 3.398482\n",
      "gen_loss_L1 0.07188192\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 23  step 112  datum 895 global_step 9000 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.331277\n",
      "gen_loss_GAN 3.6438715\n",
      "gen_loss_L1 0.07921009\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 23  step 312  datum 915 global_step 9200 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.37571695\n",
      "gen_loss_GAN 3.8558364\n",
      "gen_loss_L1 0.07246432\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 24  step 108  datum 935 global_step 9400 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.41664037\n",
      "gen_loss_GAN 3.4442165\n",
      "gen_loss_L1 0.07716605\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 24  step 308  datum 955 global_step 9600 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.23368149\n",
      "gen_loss_GAN 3.976973\n",
      "gen_loss_L1 0.070978105\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 25  step 104  datum 975 global_step 9800 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.8259452\n",
      "gen_loss_GAN 3.0746317\n",
      "gen_loss_L1 0.07832025\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 25  step 304  datum 995 global_step 10000 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.32427424\n",
      "gen_loss_GAN 3.8538454\n",
      "gen_loss_L1 0.07499471\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 26  step 100  datum 1015 global_step 10200 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.30914235\n",
      "gen_loss_GAN 3.8024547\n",
      "gen_loss_L1 0.07986914\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 26  step 300  datum 1035 global_step 10400 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.1288518\n",
      "gen_loss_GAN 4.176703\n",
      "gen_loss_L1 0.07720691\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 27  step 96  datum 1055 global_step 10600 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.283646\n",
      "gen_loss_GAN 3.8127768\n",
      "gen_loss_L1 0.078976735\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 27  step 296  datum 1075 global_step 10800 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.37490255\n",
      "gen_loss_GAN 3.8476048\n",
      "gen_loss_L1 0.07673324\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 28  step 92  datum 1095 global_step 11000 image/sec 0.0  remaining 3m\n",
      "discrim_loss 0.31017312\n",
      "gen_loss_GAN 3.6158578\n",
      "gen_loss_L1 0.07623022\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 28  step 292  datum 1115 global_step 11200 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.62537676\n",
      "gen_loss_GAN 3.8298366\n",
      "gen_loss_L1 0.07739013\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 29  step 88  datum 1135 global_step 11400 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.28715926\n",
      "gen_loss_GAN 3.8929365\n",
      "gen_loss_L1 0.07423585\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 29  step 288  datum 1155 global_step 11600 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.19929133\n",
      "gen_loss_GAN 4.1187253\n",
      "gen_loss_L1 0.0772158\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 30  step 84  datum 1175 global_step 11800 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.23790783\n",
      "gen_loss_GAN 4.194801\n",
      "gen_loss_L1 0.07473684\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 30  step 284  datum 1195 global_step 12000 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.38969442\n",
      "gen_loss_GAN 4.1011267\n",
      "gen_loss_L1 0.07969963\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 31  step 80  datum 1215 global_step 12200 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.20489828\n",
      "gen_loss_GAN 4.1051216\n",
      "gen_loss_L1 0.07384725\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 31  step 280  datum 1235 global_step 12400 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.14935781\n",
      "gen_loss_GAN 4.202617\n",
      "gen_loss_L1 0.080441594\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 32  step 76  datum 1255 global_step 12600 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.23070556\n",
      "gen_loss_GAN 4.1519556\n",
      "gen_loss_L1 0.070538\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 32  step 276  datum 1275 global_step 12800 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.17999157\n",
      "gen_loss_GAN 4.5299945\n",
      "gen_loss_L1 0.08001309\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 33  step 72  datum 1295 global_step 13000 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.11495865\n",
      "gen_loss_GAN 4.6573296\n",
      "gen_loss_L1 0.071218014\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 33  step 272  datum 1315 global_step 13200 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.27413586\n",
      "gen_loss_GAN 4.620963\n",
      "gen_loss_L1 0.08089182\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 34  step 68  datum 1335 global_step 13400 image/sec 0.0  remaining 4m\n",
      "discrim_loss 0.15564622\n",
      "gen_loss_GAN 4.509518\n",
      "gen_loss_L1 0.070606284\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 34  step 268  datum 1355 global_step 13600 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.14520152\n",
      "gen_loss_GAN 4.5753155\n",
      "gen_loss_L1 0.07981948\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 35  step 64  datum 1375 global_step 13800 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.42882538\n",
      "gen_loss_GAN 3.9234335\n",
      "gen_loss_L1 0.071361065\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 35  step 264  datum 1395 global_step 14000 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.22307464\n",
      "gen_loss_GAN 4.51593\n",
      "gen_loss_L1 0.08183795\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 36  step 60  datum 1415 global_step 14200 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.13308674\n",
      "gen_loss_GAN 4.7286882\n",
      "gen_loss_L1 0.07119101\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 36  step 260  datum 1435 global_step 14400 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.27165848\n",
      "gen_loss_GAN 4.662526\n",
      "gen_loss_L1 0.08337887\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 37  step 56  datum 1455 global_step 14600 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.106345214\n",
      "gen_loss_GAN 4.6748896\n",
      "gen_loss_L1 0.071206346\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 37  step 256  datum 1475 global_step 14800 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.25110668\n",
      "gen_loss_GAN 4.494686\n",
      "gen_loss_L1 0.08386922\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 38  step 52  datum 1495 global_step 15000 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.16886225\n",
      "gen_loss_GAN 4.559158\n",
      "gen_loss_L1 0.07667263\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 38  step 252  datum 1515 global_step 15200 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.19672124\n",
      "gen_loss_GAN 4.7468505\n",
      "gen_loss_L1 0.0868384\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 39  step 48  datum 1535 global_step 15400 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.08447908\n",
      "gen_loss_GAN 4.8545165\n",
      "gen_loss_L1 0.07977026\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 39  step 248  datum 1555 global_step 15600 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.5745302\n",
      "gen_loss_GAN 4.0095196\n",
      "gen_loss_L1 0.081918515\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 40  step 44  datum 1575 global_step 15800 image/sec 0.0  remaining 5m\n",
      "discrim_loss 0.21946767\n",
      "gen_loss_GAN 4.7478695\n",
      "gen_loss_L1 0.07099164\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 40  step 244  datum 1595 global_step 16000 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.31433246\n",
      "gen_loss_GAN 4.4078035\n",
      "gen_loss_L1 0.07608038\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 41  step 40  datum 1615 global_step 16200 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.19647059\n",
      "gen_loss_GAN 4.5428133\n",
      "gen_loss_L1 0.071683735\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 41  step 240  datum 1635 global_step 16400 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.18668541\n",
      "gen_loss_GAN 4.428041\n",
      "gen_loss_L1 0.07893831\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 42  step 36  datum 1655 global_step 16600 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.19767275\n",
      "gen_loss_GAN 4.7149177\n",
      "gen_loss_L1 0.07380287\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 42  step 236  datum 1675 global_step 16800 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.26509944\n",
      "gen_loss_GAN 4.2765903\n",
      "gen_loss_L1 0.07971326\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 43  step 32  datum 1695 global_step 17000 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.17849621\n",
      "gen_loss_GAN 4.565488\n",
      "gen_loss_L1 0.077225305\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 43  step 232  datum 1715 global_step 17200 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.22860649\n",
      "gen_loss_GAN 4.3927093\n",
      "gen_loss_L1 0.08040474\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 44  step 28  datum 1735 global_step 17400 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.18809848\n",
      "gen_loss_GAN 4.595636\n",
      "gen_loss_L1 0.07691157\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 44  step 228  datum 1755 global_step 17600 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.14755483\n",
      "gen_loss_GAN 4.6737185\n",
      "gen_loss_L1 0.07868729\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 45  step 24  datum 1775 global_step 17800 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.19071126\n",
      "gen_loss_GAN 4.5304766\n",
      "gen_loss_L1 0.07774471\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 45  step 224  datum 1795 global_step 18000 image/sec 0.0  remaining 6m\n",
      "discrim_loss 0.1891104\n",
      "gen_loss_GAN 4.8986163\n",
      "gen_loss_L1 0.07533015\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 46  step 20  datum 1815 global_step 18200 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.21537673\n",
      "gen_loss_GAN 5.1169505\n",
      "gen_loss_L1 0.07862017\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 46  step 220  datum 1835 global_step 18400 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.13360614\n",
      "gen_loss_GAN 4.9177337\n",
      "gen_loss_L1 0.07478316\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 47  step 16  datum 1855 global_step 18600 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.25441724\n",
      "gen_loss_GAN 5.110825\n",
      "gen_loss_L1 0.07627493\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 47  step 216  datum 1875 global_step 18800 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.13849449\n",
      "gen_loss_GAN 5.4840946\n",
      "gen_loss_L1 0.07142313\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 48  step 12  datum 1895 global_step 19000 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.7694104\n",
      "gen_loss_GAN 3.90894\n",
      "gen_loss_L1 0.07644027\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 48  step 212  datum 1915 global_step 19200 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.3614229\n",
      "gen_loss_GAN 3.992291\n",
      "gen_loss_L1 0.07215453\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 49  step 8  datum 1935 global_step 19400 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.21154006\n",
      "gen_loss_GAN 4.6884985\n",
      "gen_loss_L1 0.07818874\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 49  step 208  datum 1955 global_step 19600 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.27741483\n",
      "gen_loss_GAN 4.3201075\n",
      "gen_loss_L1 0.068578444\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 50  step 4  datum 1975 global_step 19800 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.18622518\n",
      "gen_loss_GAN 4.695738\n",
      "gen_loss_L1 0.07745398\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 50  step 204  datum 1995 global_step 20000 image/sec 0.0  remaining 7m\n",
      "discrim_loss 0.088238835\n",
      "gen_loss_GAN 4.925616\n",
      "gen_loss_L1 0.07184781\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 50  step 404  datum 2015 global_step 20200 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.12611462\n",
      "gen_loss_GAN 5.0699997\n",
      "gen_loss_L1 0.077486694\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 51  step 200  datum 15 global_step 20400 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.115779564\n",
      "gen_loss_GAN 4.964055\n",
      "gen_loss_L1 0.067990884\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 51  step 400  datum 35 global_step 20600 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.31076708\n",
      "gen_loss_GAN 4.498945\n",
      "gen_loss_L1 0.078947715\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 52  step 196  datum 55 global_step 20800 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.17696278\n",
      "gen_loss_GAN 4.571721\n",
      "gen_loss_L1 0.07201082\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 52  step 396  datum 75 global_step 21000 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.14133787\n",
      "gen_loss_GAN 5.201383\n",
      "gen_loss_L1 0.08291154\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 53  step 192  datum 95 global_step 21200 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.15082826\n",
      "gen_loss_GAN 5.0268016\n",
      "gen_loss_L1 0.069458455\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 53  step 392  datum 115 global_step 21400 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.20465444\n",
      "gen_loss_GAN 5.3907404\n",
      "gen_loss_L1 0.08174963\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 54  step 188  datum 135 global_step 21600 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.0901607\n",
      "gen_loss_GAN 5.1548944\n",
      "gen_loss_L1 0.07176081\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 54  step 388  datum 155 global_step 21800 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.15446876\n",
      "gen_loss_GAN 5.411623\n",
      "gen_loss_L1 0.08179381\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 55  step 184  datum 175 global_step 22000 image/sec 0.0  remaining 8m\n",
      "discrim_loss 0.2029122\n",
      "gen_loss_GAN 5.133402\n",
      "gen_loss_L1 0.07179871\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 55  step 384  datum 195 global_step 22200 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.8806395\n",
      "gen_loss_GAN 3.2796164\n",
      "gen_loss_L1 0.07787914\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 56  step 180  datum 215 global_step 22400 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.18201655\n",
      "gen_loss_GAN 4.448633\n",
      "gen_loss_L1 0.07371007\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 56  step 380  datum 235 global_step 22600 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.12543511\n",
      "gen_loss_GAN 4.819841\n",
      "gen_loss_L1 0.07846063\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 57  step 176  datum 255 global_step 22800 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.074490055\n",
      "gen_loss_GAN 5.325014\n",
      "gen_loss_L1 0.0770509\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 57  step 376  datum 275 global_step 23000 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.2732239\n",
      "gen_loss_GAN 4.706304\n",
      "gen_loss_L1 0.07734859\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 58  step 172  datum 295 global_step 23200 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.2150748\n",
      "gen_loss_GAN 4.950208\n",
      "gen_loss_L1 0.0713408\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 58  step 372  datum 315 global_step 23400 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.20523885\n",
      "gen_loss_GAN 4.905372\n",
      "gen_loss_L1 0.07938933\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 59  step 168  datum 335 global_step 23600 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.15919372\n",
      "gen_loss_GAN 4.994008\n",
      "gen_loss_L1 0.07569593\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 59  step 368  datum 355 global_step 23800 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.15398937\n",
      "gen_loss_GAN 4.8835893\n",
      "gen_loss_L1 0.077835865\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 60  step 164  datum 375 global_step 24000 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.14539109\n",
      "gen_loss_GAN 5.2528296\n",
      "gen_loss_L1 0.07706283\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 60  step 364  datum 395 global_step 24200 image/sec 0.0  remaining 9m\n",
      "discrim_loss 0.62279004\n",
      "gen_loss_GAN 4.472119\n",
      "gen_loss_L1 0.07662163\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 61  step 160  datum 415 global_step 24400 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.28158027\n",
      "gen_loss_GAN 4.8014116\n",
      "gen_loss_L1 0.07404858\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 61  step 360  datum 435 global_step 24600 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.14455318\n",
      "gen_loss_GAN 4.7719646\n",
      "gen_loss_L1 0.074132286\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 62  step 156  datum 455 global_step 24800 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.14601259\n",
      "gen_loss_GAN 5.0313897\n",
      "gen_loss_L1 0.07606435\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 62  step 356  datum 475 global_step 25000 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.071077846\n",
      "gen_loss_GAN 4.8774066\n",
      "gen_loss_L1 0.073846504\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 63  step 152  datum 495 global_step 25200 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.3660275\n",
      "gen_loss_GAN 4.449952\n",
      "gen_loss_L1 0.07420765\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 63  step 352  datum 515 global_step 25400 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.31847608\n",
      "gen_loss_GAN 4.430774\n",
      "gen_loss_L1 0.070452705\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 64  step 148  datum 535 global_step 25600 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.23185076\n",
      "gen_loss_GAN 4.7989054\n",
      "gen_loss_L1 0.07415305\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 64  step 348  datum 555 global_step 25800 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.13206974\n",
      "gen_loss_GAN 4.733441\n",
      "gen_loss_L1 0.070706025\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 65  step 144  datum 575 global_step 26000 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.2810595\n",
      "gen_loss_GAN 4.9674926\n",
      "gen_loss_L1 0.07597232\n",
      "-------------------------\n",
      "saving model\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 65  step 344  datum 595 global_step 26200 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.103476584\n",
      "gen_loss_GAN 4.837047\n",
      "gen_loss_L1 0.071416944\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 66  step 140  datum 615 global_step 26400 image/sec 0.0  remaining 10m\n",
      "discrim_loss 0.06657131\n",
      "gen_loss_GAN 4.800688\n",
      "gen_loss_L1 0.081569485\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 66  step 340  datum 635 global_step 26600 image/sec 0.0  remaining 11m\n",
      "discrim_loss 0.0747605\n",
      "gen_loss_GAN 5.0016646\n",
      "gen_loss_L1 0.07320371\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 67  step 136  datum 655 global_step 26800 image/sec 0.0  remaining 11m\n",
      "discrim_loss 0.057105403\n",
      "gen_loss_GAN 5.554826\n",
      "gen_loss_L1 0.08081478\n",
      "-------------------------\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "recording summary\n",
      "recording summary\n",
      "saving display images\n",
      "progress  epoch 67  step 336  datum 675 global_step 27000 image/sec 0.0  remaining 11m\n",
      "discrim_loss 0.1283836\n",
      "gen_loss_GAN 5.3642974\n",
      "gen_loss_L1 0.07162893\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "options = None\n",
    "run_metadata = None\n",
    "\n",
    "## Create tf session configuration\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "def get_session(sess):\n",
    "    session = sess\n",
    "    while type(session).__name__ != 'Session':\n",
    "        session = session._sess\n",
    "    return session\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "with tf.train.MonitoredTrainingSession(config=config) as sess:\n",
    "    \n",
    "    ## Unfinalize and print paramater count\n",
    "    sess.graph._unsafe_unfinalize()\n",
    "    print(\"parameter_count =\", sess.run(parameter_count))\n",
    "    \n",
    "    ## Load the latest checkpoint\n",
    "    ## if it exists\n",
    "    if output_dir is not None:\n",
    "        checkpoint_restore = tf.train.latest_checkpoint(output_dir)\n",
    "        if checkpoint_restore is not None:\n",
    "            saver.restore(sess, checkpoint_restore)  \n",
    "            print (\"Restoring, \", checkpoint_restore)\n",
    "        else:\n",
    "            print (\"No model to load ...\")\n",
    "            \n",
    "    ## Create summary writer\n",
    "    summary_writer = tf.summary.FileWriter(output_dir,sess.graph)\n",
    "\n",
    "    ## start training :)\n",
    "    print (\"Training has started! ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    global_steps = 1\n",
    "    for epoch in range(max_epochs):\n",
    "        for datum in range(0, dataset_size, batch_size):\n",
    "\n",
    "            try:\n",
    "                input_image = sess.run(input_image_next)\n",
    "                target_image = sess.run(target_image_next)\n",
    "            except:\n",
    "                print (\"Error in loading data :(((\")\n",
    "                continue\n",
    "\n",
    "            for step in range(max_steps):        \n",
    "\n",
    "                fetches = {\n",
    "                    \"train\": model.train,\n",
    "                }\n",
    "                \n",
    "                if global_steps % progress_freq == 0:\n",
    "                    fetches[\"discrim_loss\"] = model.discrim_loss\n",
    "                    fetches[\"gen_loss_GAN\"] = model.gen_loss_GAN\n",
    "                    fetches[\"gen_loss_L1\"] = model.gen_loss_L1\n",
    "\n",
    "                if global_steps % summary_freq == 0:\n",
    "                    fetches[\"summary\"] = summary_merged\n",
    "\n",
    "                if global_steps % display_freq == 0:                    \n",
    "                    fetches[\"display\"] = display_fetches\n",
    "\n",
    "                try:\n",
    "                    results = sess.run(fetches, options=options, run_metadata=run_metadata)\n",
    "                    results[\"global_step\"] = global_steps\n",
    "                except tf.errors.InvalidArgumentError as e:\n",
    "                    print (e)\n",
    "                    print (\"Error in training :(\")\n",
    "                    continue\n",
    "                    \n",
    "                if global_steps % summary_freq == 0:\n",
    "                    print(\"recording summary\")\n",
    "                    summary_writer.add_summary(results[\"summary\"], results[\"global_step\"])\n",
    "\n",
    "                if global_steps % display_freq == 0:\n",
    "                    print(\"saving display images\")\n",
    "                    display_images = results\n",
    "                    filesets = save_images(results, \n",
    "                                           step=results[\"global_step\"])\n",
    "                    append_index(filesets, step=True)\n",
    "\n",
    "                if global_steps % progress_freq == 0:\n",
    "                    \n",
    "                    steps_per_epoch = int(math.ceil(dataset_size / batch_size))\n",
    "                    train_epoch = math.ceil(results[\"global_step\"] / steps_per_epoch)\n",
    "                    train_step = (results[\"global_step\"] - 1) % steps_per_epoch + 1\n",
    "                    rate = (step + 1) * batch_size / (time.time() - start)\n",
    "                    remaining = (max_steps - step) * batch_size / rate\n",
    "                    print(\"progress  epoch %d  step %d  datum %d global_step %d image/sec %0.1f  remaining %dm\" % (train_epoch, train_step, datum, global_steps, rate, remaining / 60))\n",
    "                    print(\"discrim_loss\", results[\"discrim_loss\"])\n",
    "                    print(\"gen_loss_GAN\", results[\"gen_loss_GAN\"])\n",
    "                    print(\"gen_loss_L1\", results[\"gen_loss_L1\"])\n",
    "                    print(\"-------------------------\")\n",
    "\n",
    "                if global_steps % save_freq == 0:\n",
    "                    print(\"saving model\")\n",
    "                    \n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    \n",
    "                    saver.save(get_session(sess),\n",
    "                               os.path.join(output_dir, \"model\"),\n",
    "                               global_step=global_steps)\n",
    "                    \n",
    "                global_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "i = np.array(Image.open(io.BytesIO(display_images[\"display\"][\"inputs\"][0])))\n",
    "j = np.array(Image.open(io.BytesIO(display_images[\"display\"][\"targets\"][0])))\n",
    "o = np.array(Image.open(io.BytesIO(display_images[\"display\"][\"outputs\"][0])))\n",
    "Image.fromarray(np.hstack((i,j,o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "\"self2face-gpu\"",
   "language": "python",
   "name": "self2face-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
